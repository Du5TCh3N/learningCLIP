{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3JdWGaGnHa4LAA0go26n/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Du5TCh3N/learningCLIP/blob/main/Finetune_ViT_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this code is taken from this youtube tutorial\n",
        "https://www.youtube.com/watch?v=qU7wO02urYU"
      ],
      "metadata": {
        "id": "X7WoDf469GJJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6LV0o9N9Fbo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_train = load_dataset(\n",
        "    'cifar10',\n",
        "    split='train',\n",
        "    ignore_verifications=False\n",
        ")\n",
        "\n",
        "dataset_train"
      ],
      "metadata": {
        "id": "VRGqQOVI9ky5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = load_dataset(\n",
        "    'cifar10',\n",
        "    split='test',\n",
        "    ignore_verifications=True\n",
        ")\n",
        "\n",
        "dataset_test"
      ],
      "metadata": {
        "id": "z0OeIKOb90pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set(dataset_train['label']))\n",
        "labels = dataset_train.features['label']\n",
        "\n",
        "num_classes, labels"
      ],
      "metadata": {
        "id": "tXjCUNFy-NcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To individual training data"
      ],
      "metadata": {
        "id": "3KHw5Qi_-vbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[0]"
      ],
      "metadata": {
        "id": "1pcKaexS-z6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[0]['img']"
      ],
      "metadata": {
        "id": "seJlTAAm-1tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[0]['label'], labels.names[dataset_train[0]['label']]"
      ],
      "metadata": {
        "id": "p3OJGH-D-6Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load ViT Feature Extractor"
      ],
      "metadata": {
        "id": "L6YZanQY_C2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " from transformers import ViTImageProcessor\n",
        "\n",
        " model_name_or_path = 'laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K'\n",
        "# model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
        " feature_extractor = ViTImageProcessor.from_pretrained(\n",
        "    model_name_or_path\n",
        " )\n",
        "\n",
        " feature_extractor"
      ],
      "metadata": {
        "id": "8JOcGkVv_CmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = feature_extractor(\n",
        "    dataset_train[0]['img'],\n",
        "    return_tensors='pt'\n",
        ")\n",
        "example"
      ],
      "metadata": {
        "id": "5t2bAAyEAML0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example['pixel_values'].shape"
      ],
      "metadata": {
        "id": "iEQNdtX2AdwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the size will be different to the initial due to rescaling"
      ],
      "metadata": {
        "id": "wIybZqwpAkSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "yTOB64Q1AiD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(batch):\n",
        "  inputs = feature_extractor(\n",
        "      batch['img'],\n",
        "      return_tensors = 'pt'\n",
        "  )\n",
        "  inputs['label'] = batch['label']\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "NNlY-2mQAw8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_train = dataset_train.with_transform(preprocess)\n",
        "prepared_test = dataset_test.with_transform(preprocess)"
      ],
      "metadata": {
        "id": "OeJrFFCVA-u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we are going to build the Trainer, which is a feature-complete training and evaluation loop for PyTorch, optimized for HuggingFace Transformers.\n",
        "\n",
        "We need to define all of the arguments that it will include:\n",
        "\n",
        "\n",
        "*   training and testing dataset\n",
        "*   feature extractor\n",
        "*   model\n",
        "*   collate function\n",
        "*   evaluation metric\n",
        "*   ... other training arguments\n",
        "\n"
      ],
      "metadata": {
        "id": "G860DhWSBRY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  return {\n",
        "      'pixel_values' : torch.stack([x['pixel_values'] for x in batch]),\n",
        "      'labels' : torch.tensor([x['label'] for x in batch])\n",
        "  }"
      ],
      "metadata": {
        "id": "qG8Pc__XBrOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric('accuracy')\n",
        "def compute_metrics(p):\n",
        "  return metric.compute(\n",
        "      predictions = np.argmax(p.predictions, axis = 1),\n",
        "      references = p.label_ids\n",
        "  )"
      ],
      "metadata": {
        "id": "ZGbmCZzvCBR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = './cifar',\n",
        "    per_device_train_batch_size = 16,\n",
        "    evaluation_strategy = \"steps\",\n",
        "    num_train_epochs = 4,\n",
        "    save_steps = 100,\n",
        "    eval_steps = 100,\n",
        "    logging_steps = 10,\n",
        "    learning_rate = 2e-4,\n",
        "    save_total_limit = 2,\n",
        "    remove_unused_columns = False,\n",
        "    push_to_hub = False,\n",
        "    load_best_model_at_end = True,\n",
        ")"
      ],
      "metadata": {
        "id": "XXByjhryCUEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTForImageClassification\n",
        "\n",
        "labels = dataset_train.features['label'].names\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    num_labels = len(labels)\n",
        ")"
      ],
      "metadata": {
        "id": "I_ngfZ92DCfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator = collate_fn,\n",
        "    compute_metrics = compute_metrics,\n",
        "    train_dataset = prepared_train,\n",
        "    eval_dataset = prepared_test,\n",
        "    tokenizer = feature_extractor,\n",
        ")"
      ],
      "metadata": {
        "id": "ARkwIJ6oHCBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = trainer.train()\n",
        "\n",
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "W_D-fbhHJrE_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}